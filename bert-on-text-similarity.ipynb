{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretrained-bert-including-scripts', 'quora-question-pairs', 'kerasbert']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** BERT pretrained directory: ../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12 *****\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "sys.path.insert(0, '../input/pretrained-bert-including-scripts/master/bert-master')\n",
    "!cp -r '../input/kerasbert/keras_bert' '/kaggle/working'\n",
    "BERT_PRETRAINED_DIR = '../input/pretrained-bert-including-scripts/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12'\n",
    "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
    "import tokenization  #Actually keras_bert contains tokenization part, here just for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training data\n",
    "train_df = pd.read_csv('../input/quora-question-pairs/train.csv')\n",
    "#train_df = train_df.sample(frac=0.1,random_state = 42)\n",
    "test_df = pd.read_csv('../input/quora-question-pairs/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.630802\n",
       "1    0.369198\n",
       "Name: is_duplicate, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_duplicate.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question1'] = train_df.question1.astype(str)\n",
    "train_df['question2']  = train_df.question2.astype(str)\n",
    "test_df['question1']  = test_df.question1.astype(str)\n",
    "test_df['question2']  = test_df.question2.astype(str)\n",
    "\n",
    "train_df['question1_len'] = train_df.question1.apply(lambda x: len(x.split()))\n",
    "train_df['question2_len']  = train_df.question2.apply(lambda x: len(x.split()))\n",
    "test_df['question1_len']  = test_df.question1.apply(lambda x: len(x.split()))\n",
    "test_df['question2_len']  = test_df.question2.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_len</th>\n",
       "      <th>question2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "      <td>404290.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>217243.942418</td>\n",
       "      <td>220955.655337</td>\n",
       "      <td>0.369198</td>\n",
       "      <td>10.942210</td>\n",
       "      <td>11.181991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116708.614502</td>\n",
       "      <td>157751.700002</td>\n",
       "      <td>159903.182629</td>\n",
       "      <td>0.482588</td>\n",
       "      <td>5.428824</td>\n",
       "      <td>6.305246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>202144.500000</td>\n",
       "      <td>192182.000000</td>\n",
       "      <td>197052.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>363860.100000</td>\n",
       "      <td>456674.200000</td>\n",
       "      <td>461904.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>384074.550000</td>\n",
       "      <td>496522.550000</td>\n",
       "      <td>499507.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>400246.110000</td>\n",
       "      <td>529543.220000</td>\n",
       "      <td>530166.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>404289.000000</td>\n",
       "      <td>537932.000000</td>\n",
       "      <td>537933.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id           qid1      ...        question1_len  question2_len\n",
       "count  404290.000000  404290.000000      ...        404290.000000  404290.000000\n",
       "mean   202144.500000  217243.942418      ...            10.942210      11.181991\n",
       "std    116708.614502  157751.700002      ...             5.428824       6.305246\n",
       "min         0.000000       1.000000      ...             1.000000       1.000000\n",
       "50%    202144.500000  192182.000000      ...            10.000000      10.000000\n",
       "90%    363860.100000  456674.200000      ...            18.000000      19.000000\n",
       "95%    384074.550000  496522.550000      ...            22.000000      24.000000\n",
       "99%    400246.110000  529543.220000      ...            29.000000      33.000000\n",
       "max    404289.000000  537932.000000      ...           125.000000     237.000000\n",
       "\n",
       "[9 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(percentiles = [0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "weight_decay = 0.001\n",
    "nb_epochs=1\n",
    "bsz = 32\n",
    "maxlen1 = 30\n",
    "maxlen2 = 30\n",
    "maxlen = maxlen1+maxlen2+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_len</th>\n",
       "      <th>question2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2      ...       is_duplicate question1_len  question2_len\n",
       "0   0     1     2      ...                  0            14             12\n",
       "1   1     3     4      ...                  0             8             13\n",
       "2   2     5     6      ...                  0            14             10\n",
       "3   3     7     8      ...                  0            11              9\n",
       "4   4     9    10      ...                  0            13              7\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['comment_text'] = train_df['comment_text'].replace({r'\\s+$': '', r'^\\s+': ''}, regex=True).replace(r'\\n',  ' ', regex=True)\n",
    "train_lines1, train_lines2, train_labels = train_df['question1'].values, train_df['question2'].values, train_df.is_duplicate.values \n",
    "test_lines1, test_lines2 = test_df['question1'].values, test_df['question2'].values\n",
    "## step parameter \n",
    "decay_steps = int(nb_epochs*train_lines1.shape[0]/bsz)\n",
    "warmup_steps = int(0.0001*decay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin_build\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras_bert.keras_bert.bert import get_model\n",
    "from keras_bert.keras_bert.loader import load_trained_model_from_checkpoint\n",
    "print('begin_build')\n",
    "\n",
    "config_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "checkpoint_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True,seq_len=maxlen)\n",
    "#model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "class AdamWarmup(keras.optimizers.Optimizer):\n",
    "    def __init__(self, decay_steps, warmup_steps, min_lr=0.0,\n",
    "                 lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, kernel_weight_decay=0., bias_weight_decay=0.,\n",
    "                 amsgrad=False, **kwargs):\n",
    "        super(AdamWarmup, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.decay_steps = K.variable(decay_steps, name='decay_steps')\n",
    "            self.warmup_steps = K.variable(warmup_steps, name='warmup_steps')\n",
    "            self.min_lr = K.variable(min_lr, name='min_lr')\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.kernel_weight_decay = K.variable(kernel_weight_decay, name='kernel_weight_decay')\n",
    "            self.bias_weight_decay = K.variable(bias_weight_decay, name='bias_weight_decay')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_kernel_weight_decay = kernel_weight_decay\n",
    "        self.initial_bias_weight_decay = bias_weight_decay\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "        lr = K.switch(\n",
    "            t <= self.warmup_steps,\n",
    "            self.lr * (t / self.warmup_steps),\n",
    "            self.lr * (1.0 - K.minimum(t, self.decay_steps) / self.decay_steps),\n",
    "        )\n",
    "\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        else:\n",
    "            vhats = [K.zeros(1) for _ in params]\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                p_t = m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                p_t = m_t / (K.sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            if 'bias' in p.name or 'Norm' in p.name:\n",
    "                if self.initial_bias_weight_decay > 0.0:\n",
    "                    p_t += self.bias_weight_decay * p\n",
    "            else:\n",
    "                if self.initial_kernel_weight_decay > 0.0:\n",
    "                    p_t += self.kernel_weight_decay * p\n",
    "            p_t = p - lr_t * p_t\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'decay_steps': float(K.get_value(self.decay_steps)),\n",
    "            'warmup_steps': float(K.get_value(self.warmup_steps)),\n",
    "            'min_lr': float(K.get_value(self.min_lr)),\n",
    "            'lr': float(K.get_value(self.lr)),\n",
    "            'beta_1': float(K.get_value(self.beta_1)),\n",
    "            'beta_2': float(K.get_value(self.beta_2)),\n",
    "            'epsilon': self.epsilon,\n",
    "            'kernel_weight_decay': float(K.get_value(self.kernel_weight_decay)),\n",
    "            'bias_weight_decay': float(K.get_value(self.bias_weight_decay)),\n",
    "            'amsgrad': self.amsgrad,\n",
    "        }\n",
    "        base_config = super(AdamWarmup, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import re\n",
    "import codecs\n",
    "adamwarm = AdamWarmup(lr=lr,decay_steps = decay_steps, warmup_steps = warmup_steps,kernel_weight_decay = weight_decay)\n",
    "\n",
    "sequence_output = model.layers[-6].output\n",
    "pool_output = Dense(1, activation='sigmoid', kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),name = 'real_output')(sequence_output)\n",
    "model3 = Model(inputs=model.input, outputs=pool_output)\n",
    "model3.compile(loss='binary_crossentropy', optimizer=adamwarm)\n",
    "#model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build tokenizer done\n",
      "sample used (404290,)\n",
      "12602\n",
      "(404290, 63)\n",
      "(404290, 63)\n",
      "(404290, 63)\n",
      "begin training\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1\n",
      "190272/404290 [=============>................] - ETA: 29:59 - loss: 0.1505"
     ]
    }
   ],
   "source": [
    "def convert_lines(example1, example2, max_seq_length1,max_seq_length2,tokenizer):\n",
    "    #max_seq_length1=2\n",
    "    #max_seq_length2-=1\n",
    "    all_tokens = []\n",
    "    longer1 = 0\n",
    "    longer2 = 0\n",
    "    for i in range(example1.shape[0]):\n",
    "        tokens_a1 = tokenizer.tokenize(example1[i])\n",
    "        tokens_a2 = tokenizer.tokenize(example2[i])\n",
    "        if len(tokens_a1)>max_seq_length1:\n",
    "            tokens_a1 = tokens_a1[:max_seq_length1]\n",
    "            longer1 += 1\n",
    "        if len(tokens_a2)>max_seq_length2:\n",
    "            tokens_a2 = tokens_a2[:max_seq_length2]\n",
    "            longer2 += 1\n",
    "        one_token = tokenizer.convert_tokens_to_ids(([\"[CLS]\"]+tokens_a1))+\\\n",
    "                            [0]*(max_seq_length1-len(tokens_a1))+(tokenizer.convert_tokens_to_ids([\"[SEP]\"]+tokens_a2)+\\\n",
    "                                              [0]*(max_seq_length2-len(tokens_a2)))+tokenizer.convert_tokens_to_ids([\"[SEP]\"])\n",
    "        all_tokens.append(one_token)\n",
    "    print(longer1)\n",
    "    return np.array(all_tokens)\n",
    "    \n",
    "\n",
    "dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=dict_path, do_lower_case=True)\n",
    "print('build tokenizer done')\n",
    "print('sample used',train_lines1.shape)\n",
    "token_input = convert_lines(train_lines1,train_lines2, maxlen1, maxlen2, tokenizer)\n",
    "seg_input = np.zeros((token_input.shape[0],maxlen))\n",
    "mask_input = np.ones((token_input.shape[0],maxlen))\n",
    "print(token_input.shape)\n",
    "print(seg_input.shape)\n",
    "print(mask_input.shape)\n",
    "print('begin training')\n",
    "class_weight = {0:0.630802, 1:0.369198}\n",
    "model3.fit([token_input, seg_input, mask_input],train_labels,batch_size=bsz,epochs=nb_epochs, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88100\n"
     ]
    }
   ],
   "source": [
    "token_input_test = convert_lines(test_lines1,test_lines2, maxlen1, maxlen2, tokenizer)\n",
    "seg_input_test = np.zeros((token_input_test.shape[0],maxlen))\n",
    "mask_input_test = np.ones((token_input_test.shape[0],maxlen))\n",
    "\n",
    "preds = model3.predict([token_input_test, seg_input_test, mask_input_test],batch_size=bsz)\n",
    "submission = pd.DataFrame(index = test_df.index, columns = ['test_id', 'is_duplicate'])\n",
    "submission['test_id'] = test_df.index\n",
    "submission['is_duplicate'] = preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
